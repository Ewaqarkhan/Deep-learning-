{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7741a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccaff69",
   "metadata": {},
   "source": [
    "### Outline\n",
    "\n",
    "In Part A, you will be implementing a function for 2D convoulution. You will be implementing the following functions:\n",
    "\n",
    "- Convolution functions:\n",
    "    - Zero Padding\n",
    "    - Convolve Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6c8a3e",
   "metadata": {},
   "source": [
    "#### Zero-Padding\n",
    "\n",
    "Zero-padding adds zeros around the border of an image:\n",
    "\n",
    "The main benefits of padding are the following:\n",
    "\n",
    "- It allows you to use a CONV layer without necessarily shrinking the height and width of the volumes. This is important for building deeper networks, since otherwise the height/width would shrink as you go to deeper layers. An important special case is the \"same\" convolution, in which the height/width is exactly preserved after one layer. \n",
    "\n",
    "- It helps us keep more of the information at the border of an image. Without padding, very few values at the next layer would be affected by pixels as the edges of an image.\n",
    "\n",
    "\n",
    "Implement the <code>zero_pad</code> function which will pad the image. Use <code>np.pad</code> to do this (Look up the documentation to figure out the arguments for padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d18e92f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc8e6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- python numpy array of shape (n_H, n_W) representing a an image\n",
    "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
    "    \"\"\"\n",
    "    #your code goes here\n",
    "    #check np.pad()\n",
    "    X_pad = np.pad(X, ((0, 0), (pad, pad), (pad, pad), (0, 0)), 'constant', constant_values=0)\n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf529151",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(3, 3)\n",
    "x_pad = zero_pad(x, 2)\n",
    "\n",
    "print(\"Shape of x_pad: \", x_pad.shape)\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2)\n",
    "axarr[0].set_title('x')\n",
    "axarr[0].imshow(x,cmap='gray')\n",
    "axarr[1].set_title('x_pad')\n",
    "axarr[1].imshow(x_pad,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eb37a3",
   "metadata": {},
   "source": [
    "#### 2D Convolution\n",
    "\n",
    "In this part, implement a 2D convolution, in which you apply the filter to aa image. This will be used to build a convolutional unit, which: \n",
    "\n",
    "- Takes an input image \n",
    "- Applies a filter at every position of the input\n",
    "- Outputs another image (usually of different size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "727615b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2D(inp, F, pad, stride):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    inp -- output activations of the previous layer, numpy array of shape (n_H, n_W)\n",
    "    F -- Filter, numpy array of shape (f, f)\n",
    "    pad -- integer\n",
    "    stride -- integer\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve dimensions from inp's shape\n",
    "    (n_H, n_W) = inp.shape\n",
    "    \n",
    "    # Retrieve dimensions from F's shape\n",
    "    (f, f) = F.shape\n",
    "    \n",
    "    ########## START CODE HERE ##########\n",
    "    # Compute the dimensions of the CONV output volume (Hint: use int() to floor the output)\n",
    "    \n",
    "    \n",
    "    # Initialize the output volume Z with zeros\n",
    "    \n",
    "    # Create inp_pad by padding inp\n",
    "\n",
    "    # Iterate over inp and compute its Convolved output (z) and store it appropriately in Z.\n",
    "    \n",
    "    ########## END CODE HERE ##########\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d1357e",
   "metadata": {},
   "source": [
    "#### Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63051eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and display duck.jpg (Hint: for reading image see cv2.imread)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fddaea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert duck to grayscale (Hint: see cv2.cvtColor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aeb7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sobel horizontal edge filter\n",
    "\n",
    "\n",
    "# Use your Conv2D filter to get horizontal edges and display them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee7728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sobel vertical edge filter\n",
    "\n",
    "\n",
    "# Use your Conv2D filter to get vertical edges and display them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9df308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine horizontal and vertical edges and display the final results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e18f632",
   "metadata": {},
   "source": [
    "#### Filter Bank\n",
    "\n",
    "In this part you will make a filter bank for skin textures given in skins folder and then use those to classify 'unknown.jpg'. You will perform the following steps:\n",
    "\n",
    "- Read skin images and convert them to grayscale.\n",
    "- Resize the images to 64x64. (Hint: see cv2.resize).\n",
    "- Initialize any 6 filters. This will be your filter bank. \n",
    "- Create a 6D feature vector for each image using window size of 8. (Use your Conv2D function for this).\n",
    "- Display each feature vector as an image i.e. use plt.imshow.\n",
    "- Do the above steps for unknown.jpg and calculate it's feature vector.\n",
    "- Calculate and display the equilidean distance of unknown.jpg's feature with each of skin's feature vector.\n",
    "- Predict the class name of unknown.jpg based on the euclidean distances calculated in previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff1dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "#Your code goes here! follow the instructions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}